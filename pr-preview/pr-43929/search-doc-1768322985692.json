{"searchDocs":[{"title":"Camunda Platform Documentation","type":0,"sectionRef":"#","url":"/camunda/pr-preview/pr-43929/","content":"Camunda Platform Documentation This documentation is continuously updated. If you find issues or have suggestions, please contribute via GitHub.","keywords":"","version":null},{"title":"Release Process","type":0,"sectionRef":"#","url":"/camunda/pr-preview/pr-43929/release/","content":"","keywords":"","version":null},{"title":"Scope & Goal‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#scope--goal","content":" The goal of the C8 monorepo release process is to produce artifacts for patch, alpha and minor version releases of Camunda 8 components like Zeebe and (on 8.6+) most C8 webapps for SaaS and Self-Managed usage in a timely fashion. This includes the ZPT (zeebe-process-test) project. Optimize is released separately for 8.6 to 8.8 (at least).  It also involves automated and manual QA activities on release candidate builds to ensure bug-free artifacts on the final artifacts, e.g. certain benchmarks for Zeebe and interactive tests for C8 webapps.  Required inputs:  version of camunda-cloud/identity to use for any given C8 monorepo releasewhether a release candidate build and manual QA is necessary for patch releases  Produced artifacts include Maven artifacts on Maven Central, Docker images on DockerHub, GitHub releases with release notes and announcements.  There must not be 2 concurrent releases ongoing with the same major and minor version (e.g. no 8.99.1 and 8.99.2 patch releases at the same time).  Caveat: Many places still refer to this process as ‚ÄúZeebe release process‚Äù although with 8.6+ it is the monorepo release process also involving other components like C8 webapps.  Not in scope of this process are SNAPSHOT releases.  ","version":null,"tagName":"h2"},{"title":"Release Types‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#release-types","content":" Minor (version format is 8.x.0): includes new features, for production useusually released every 6 monthssupported for certain time with new patch releases after the minor releasecode freeze before the release, to allow QA on a release candidate buildsource branch is stable/${minor_version} Alpha (version format 8.x.0-alphaN) includes new features to get early customer feedback, not for production useusually released every 1 monthcode freeze before the release, to allow QA on a release candidate buildsource branch is main Patch (version format 8.x.y): includes security updates and bug fixes, for production useusually released every 1 month (or on demand, e.g. if critical CVE needs to be fixed sooner)no code freeze and no release candidate buildsource branch is stable/${minor_version}  ","version":null,"tagName":"h3"},{"title":"Release Dependencies‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#release-dependencies","content":" Caveat: While Optimize is part of the C8 monorepo, it has its own release process separate from the C8 monorepo release process (covers only Operate/Tasklist/Zeebe).  Component releases that the C8 monorepo releases depend on:  camunda-cloud/identity  Components that depend on the C8 monorepo releases:  C8 SaaSHelm ChartC8 Optimize  ","version":null,"tagName":"h3"},{"title":"Artifacts‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#artifacts","content":" Maven CentralDockerHub: ZeebeOperateTasklistOptimizeCamunda (future &quot;Single Application&quot; Docker image) GitHub releasesSBOM information on FOSSA  ","version":null,"tagName":"h3"},{"title":"Implementation‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#implementation","content":" The C8 monorepo release process is implemented using BPMN models orchestrated by Camunda 8 SaaS, GitHub Action workflows and manual tasks (called &quot;User tasks&quot;). The GitHub Action workflows listen on webhook events via the repository_dispatch mechanism. Those events are generated by C8 via the GitHub API.  ","version":null,"tagName":"h2"},{"title":"BPMN models‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#bpmn-models","content":" The BPMN models are developed, versioned and tested in this (internal) repository. BPMN models for noteworthy processes are:  Camunda Patch Release: is run for performing patch releases for versions 8.6+. Gathers the required inputs from the release manager and then starts ‚ÄúCamunda Release‚Äù processCamunda Release: Implements a unified release process for all release type since version 8.6: is started by the release manager with all the required inputs.for non-patch releases waits for code freeze time.performs the release process including artifact generation, uploads and QA, for a specific version  Caveat: Some places still refer to those BPMN models as ‚ÄúZeebe Release‚Äù although with 8.6+ the processes are responsible for multiple components including Zeebe and C8 webapps.  Resources:  Free BPMN course on Camunda Academy(Internal) Recording on the release process implementation  ","version":null,"tagName":"h3"},{"title":"Runtime‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#runtime","content":" Those BPMN models are tested and deployed from main via GitHub Actions into an (internal) Camunda 8 SaaS cluster. Resources:  Camunda Release process in OperateUser tasks in Tasklist  Secrets are configured as part of the C8 SaaS cluster and available ones are for APIs of e.g. GitHub, Slack, Opsgenie, Testrail. Used C8 connectors:  GitHub WebhookHTTP (for other APIs)Slack (mainly for notifications)  ","version":null,"tagName":"h3"},{"title":"GitHub Action workflows‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#github-action-workflows","content":" Centerpiece for the camunda/camunda monorepo is a reusable workflow on main and each stable/* branch. This workflow handles the full release pipeline: building, scanning, publishing artifacts and Docker images, and notifying teams via Slack.  üîß How It's Triggered  Releases are triggered in two ways:  For dry runs, by using on: schedule triggers defined in the workflow itself (no Slack noise here). For real releases, by calling the GitHub Actions REST API directly with a workflow_dispatch request: curl -X POST https://api.github.com/repos/camunda/camunda/actions/workflows/camunda-platform-release.yml/dispatches \\ -H &quot;Authorization: token $TOKEN&quot; \\ -d '{&quot;ref&quot;: &quot;stable/8.7&quot;, &quot;inputs&quot;: {&quot;releaseVersion&quot;: &quot;8.7.x&quot;, &quot;nextDevelopmentVersion&quot;: &quot;8.7.y-SNAPSHOT&quot;, ...}}'   üìù This replaces the older dispatch-release-* workflows, which have now been removed.  For the ZPT (zeebe-process-test) project there is automation to create the release branch, build and upload the Maven artifacts, only merging a release branch is manual.  ","version":null,"tagName":"h3"},{"title":"Benchmark Tests‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#benchmark-tests","content":" ü§î What are the benchmarks  There‚Äôs a GKE Kubernetes cluster to run the benchmarks: GCP project: zeebe-io, cluster name: zeebe-clusterRun by the Zeebe team This Kubernetes cluster has a monitoring stack installed (Prometheus, Grafana) There‚Äôs a dashboard to observe the status of the benchmarks Every created benchmark has a dedicated namespace in the Kubernetes cluster (e.g. release-8-7-x)There's a benchmark for every currently supported (maintained) version + previously released alpha version.A benchmark is installed/upgraded by this GHA workflow Under the hood, it‚Äôs running a helm install --upgrade command for a benchmark creation/updateHelm installs a special Helm chart that is a thin wrapper around the standard Camunda 8 Helm chart, with additional components for benchmark testing (workload generators)  üçÉ Benchmark flow  A benchmark is automatically created via GitHub Action call after a release candidate (RC) is triggered (GHA workflow) Benchmark creation applies only to alpha, minor, and major releases.Patches don't require a new benchmark creation. What is required is to re-use the same namespace + the recently released patch version, and update the the applicable benchmark with the newest patch version. If during the release, new commits are merged into the release branch (major, minor, alpha), the corresponding benchmark needs to be updated to run the code from latest commit of the release branch.At end end of the release process: For the alpha/minor/major release, a benchmark for this version is to be updated to its latest image (i.e. no RC running in the benchmark) E.g. if a version 8.8.0 is released, the benchmark should be running 8.8.0 not 8.8.0-RC1Additionally, for alpha releases, previous alpha for the current version is to be removed E.g. if 8.8.0-alpha6 is released, a benchmark for 8.8.0-alpha5 is be removed, for 8.8.0-alpha6 running For the patch releases, a benchmark for this minor version is to be update to this version) E.g. if a version 8.7.10 is released, the benchmark for 8.7 (release-8-7-x) will be updated to use this version as a part of the 8.7.10 patch release.  üìÅ Example  Release Version\tBenchmark Namespace in Kubernetes\tPatch Release\tAlpha Release8.5.x\trelease-8-5-x\t‚Ä¢ Update benchmark to use newly released image version via GHA workflow ‚Ä¢ Other benchmarks are untouched\t(does not happen) 8.6.x\trelease-8-6-x\t‚Ä¢ Update benchmark to use newly released image version via GHA workflow ‚Ä¢ Other benchmarks are untouched\t(does not happen) 8.7.x\trelease-8-7-x\t‚Ä¢ Update benchmark to use newly released image version via GHA workflow ‚Ä¢ Other benchmarks are untouched\t(does not happen) 8.8.0-alphaN\trelease-8-8-0-alphaN\t(does not happen)\t‚Ä¢ release-8.8.0-alphaN and release-8.8.0-alpha(N+1) benchmarks coexist during the release of release-8.8.0-alpha(N+1) ‚Ä¢ after 8.8.0-alpha(N+1) release ‚Üí release-8-8-0-alphaN is deleted ‚Ä¢ Other benchmarks are untouched  More details on how benchmark tests work can be found in our reliability testing documentation.  ","version":null,"tagName":"h3"},{"title":"Camunda 8 Testing Clusters‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#camunda-8-testing-clusters","content":" Camunda 8 testing clusters provide isolated environments for validating release builds, executing targeted test flows, and verifying features and bug fixes across all core components. The cluster creation and management processes can be manual or automated depending on the test type and the stage of the monorepo release process.  üì° Cluster Usage Scenarios  Component Coverage: Identity, Operate, Optimize, and Tasklist.Pre-release Validation: Isolate new release builds before broad deployment and confirm fixes or features behave as expected.Test Isolation: Support E2E, chaos, benchmark, reliability, andload test types.  üöÇ Monorepo Release Process Mapping  Manual Clusters  Clusters are provisioned manually for manual testing flows. They are used to enable Webapp testing across the four main apps (Identity, Operate, Optimize, and Tasklist).Manual creation is carried out by QA engineers via UI - soon to be automated by CAMUNDA-32765. The process follows qa_manual_create_cluster.md. For each Release Candidate, a new manual test cluster generation is created with the current RC version.  Automated Clusters  Automated flows use GitHub workflows like: zeebe-qa-testbench.yaml and zeebe-testbench.yaml to orchestrate the creation of clusters for benchmark, reliability, E2E, and chaos tests.The clusters for automated tests are created for every Release Candidate, mirroring the manual flow but managed programmatically.Additional details about test setup can be found in our reliability testing documentation.  üë• Ownership and Terminology  Manual Test Clusters and Manual Tests: Owned by QA engineers.Automated Test Clusters and Automated Tests: Development &amp; Maintainability owned by the Zeebe team, Release monitoring owned by Monorepo Release Manager, orchestrated via GitHub Actions.Post-release QA: Historically managed by the Monorepo Release Manager.Terminology Note: The label ‚ÄúQA‚Äù is a catch-all for testing steps in the release process, not a strict indicator of team ownership. Consider replacing ‚ÄúQA‚Äù with more precise terms such as ‚ÄúTest Validation‚Äù or ‚ÄúRelease Testing‚Äù for documentation clarity. (CAMUNDA-35223)  ","version":null,"tagName":"h3"},{"title":"Best Practices‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#best-practices","content":" For BPMN User Tasks:  Assign on creation automatically to the correct person for better UX and ownership  For BPMN activities using REST connector:  Configure retries with appropriate interval for idempotent requests, to workaround network problems/short service interruption e.g. use 3 retries with 10 seconds interval on GET requests HTTP error handling of the remote API via escalation events Also consider using retries for transient errorse.g. send a notification via Slack in #top-monorepo-release Use authentication to avoid API ratelimits of GitHub and DockerHub for increased reliability  Calling and integrating with GitHub Actions workflows:  Use C8 REST connector to call GitHub REST API to dispatch workflowsUse GHA workflow_dispatch inputs to give custom data as parameters like release branch names or versionsAvoid release managers polling for GHA workflow completion either by: Create 2nd BPMN activity that queries completion in a loop and makes the process wait for GHASend a Slack notification from GHA workflow in #top-monorepo-release to notify the release manager  ","version":null,"tagName":"h3"},{"title":"Change Management & Testing‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#change-management--testing","content":" Changes to the release process are done in these steps:  Implementation: Check out this (internal) repository locallyUse the Desktop Modeler locally to modify the BPMN modelsAdjust/extend the Java/Kotlin unit tests covering the relevant BPMN modelsCreate a Pull Request against main including screenshots + description to explain the change Testing: If testable in isolation/with dry run: demonstrate that change worksIf not testable with dry run: wait for next release Review: Get a peer review from a Monorepo DevOps team member or C8 engineer familiar with the process Rollout: Merge the Pull RequestIf necessary, migrate currently running process instances in Operate to new version of the process  ","version":null,"tagName":"h2"},{"title":"Issue Tracking‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#issue-tracking","content":" All problems, bugs and feature requests regarding the C8 release process are tracked usingGitHub Issues.  For visibility and prioritization there is the (internal) Monorepo Release project board that tracks high-level issues.  For CI-related issues in the release process, also see our CI &amp; Automation documentation.  ","version":null,"tagName":"h2"},{"title":"DRIs‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#dris","content":" This section is subject to change in #28528.  ","version":null,"tagName":"h2"},{"title":"Release Manager‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#release-manager","content":" There is one DRI called the ‚Äúmonorepo release manager‚Äù who oversees all running and newly launched release process instances end-to-end and is responsible for successfully finishing the releases (8.6+) according to their timelines. This DRI rotates every month (Slack groups etc. are manually updated) at the start of the month. Handover notes are documented in tabs here.  Some tasks during the release process are also taking care of other DRIs. The release manager can also rely on help from medics.  The release manager is currently selected manually for each release.  Caveat: Some places still refer to this as ‚ÄúZeebe release manager‚Äù although with 8.6+ the release manager is responsible for multiple components including Zeebe and C8 webapps.  ","version":null,"tagName":"h3"},{"title":"Others‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#others","content":" QA Release Manager: can help with questions around steps the QA team performs.  Caveat: Not all steps with &quot;QA&quot; in the name mean that the QA team is actually involved, so check twice  Zeebe Release Manager: can help with Zeebe-specific questions and tasks.  ","version":null,"tagName":"h3"},{"title":"Backporting Guidelines‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#backporting-guidelines","content":" We want the release process for all supported versions 8.6+ to be as similar as possible, to reduce maintenance effort, surprises and mental load. Improvements and fixes to the release process should always apply to all supported versions, if possible.  For CI-related changes, refer to our CI &amp; Automation documentation and the GitHub wiki guidelines.  ","version":null,"tagName":"h2"},{"title":"Minor Release Considerations‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#minor-release-considerations","content":" Minor releases happen less often than other release types, so not all steps are automated (yet) in the camunda/camunda monorepo:  Bump the pom.xml versions to 8.(x+1).0-SNAPHOT on main, after the last release-8.x.0-alphaN branch is created This may reveal implicit assumptions or actual bugs in upgrade tests that check for clean upgrade behavior of the software between different minor versions!This can be done with the following command ./mvnw release:update-versions -DdevelopmentVersion=8.(x+1).0-SNAPSHOT Create the stable/8.x release branch from latest release-8.x.0-alphaN, to enforce code freeze Ensure all expected SNAPSHOT artifacts are produced correctly. Configure unified-ci-merges-stable-branches branch protection ruleset to include new stable/8.x branch This may need temporary admin permissions for the initial manual push of the new branch. Bump configured versions in upgrade tests of the previous minor version to 8.x TODO: add references to known upgrade tests if possible  Also, we have to do similar steps for the ZPT repository in coordination with stakeholders from Camunda Ex team:  Creating stable/8.x release branch from main, to enforce code freezeBumping pom.xml versions to 8.(x+1).0-SNAPHOT on main  Additional Minor Release Learnings (8.8+)‚Äã  In addition to the standard steps above, recent minor releases have surfaced several process improvements and considerations worth incorporating into future release cycles:  Feature Freeze Communication The freeze notice should clearly describe not just alpha branch behavior, but expectations for the entire minor release phase (including post-alpha, backports to stable/&lt;minor&gt;, etc.).Current notice is too narrow; see engineering-processes#712 and Slack discussion.Action: Iterate a more generic, minor-release‚Äìaware template for next minor releases. Benchmark Namespace Naming Namespace for benchmarks during RCs may become 8-8-0 (when performing RC) instead of the expected 8-8-x.Current handling is accepted; document and monitor naming in future minors for reproducibility. Merge-Back Conflicts Merge conflicts can occur when merging the release branch back into stable/&lt;minor&gt;, especially due to timing of backports versus release branch changes.Reference: Slack threadAction: Evaluate sources and refine merge sequencing guidelines. Heavy Merge-Back CI Load Merge-back PRs currently run almost the full test matrix, resulting in long CI runtimes (see example run).Action: The task https://github.com/camunda/camunda/issues/39659 was created to fix the existing issue and optimize merge-back test scope or introduce selective module test strategies. Change of source branch For 8.8 minor release the source branch stable/8.8 based on release-8.8.0-alpha8Currently an automated script decides the source branch for the release type, in case of change in future release process, the code needs to be adjusted here  ","version":null,"tagName":"h2"},{"title":"Troubleshooting‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#troubleshooting","content":" ","version":null,"tagName":"h2"},{"title":"How to correlate Git commits with deployed process version in C8 Operate?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#how-to-correlate-git-commits-with-deployed-process-version-in-c8-operate","content":" There is currently no way to see metadata (e.g. deploy timestamp) in or download BPMN XML for a certain version from Operate UI.  Workaround: Open a process instance in the Operate UI and use network tab of browser and look at /xml endpoint response after a page refresh.  ","version":null,"tagName":"h3"},{"title":"I lack permissions in the (internal) Camunda 8 SaaS cluster?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#i-lack-permissions-in-the-internal-camunda-8-saas-cluster","content":" Reach out via Slack to ask for the permissions.  ","version":null,"tagName":"h3"},{"title":"How to retry a camunda-platform-release.yml job that failed mid-build?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#how-to-retry-a-camunda-platform-releaseyml-job-that-failed-mid-build","content":" The camunda-platform-release.yml GHA workflow uploads artifacts (Maven, Docker) to certain 3rd party services. If it fails unexpectedly after having already uploaded some, but not all artifacts, there is some cleanup needed. Only after the cleanup you can retry safely:  Procedure:  remove new info on GitHub (reset branch to before new Git commits, delete new Git tag)drop staged Maven artifacts from Maven Centraldo nothing re Artifactory (artifacts will be overwritten)do nothing re DockerHub (artifacts will be overwritten)retrigger the failing camunda-platform-release.yml job  ","version":null,"tagName":"h3"},{"title":"I want/need to retry/skip certain parts of a BPMN process?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#i-wantneed-to-retryskip-certain-parts-of-a-bpmn-process","content":" In C8 Operate, you can use process instance modification to change variables of the process or move to a different activity. If that activity is earlier in the process, it will be retried. If it is later, it will skip intermediate steps.  All of the above operations can be dangerous and lead to unexpected behavior or inconsistencies (outdated/lacking variables, lacking preconditions for later steps, duplicate effects that are visible externally). Proceed with caution and ask another engineer to review beforehand!  ","version":null,"tagName":"h3"},{"title":"How to remove accidentially published artifacts from Artifactory?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#how-to-remove-accidentially-published-artifacts-from-artifactory","content":" As a first step, you need to find out how to best identify the artifacts to be deleted:  Do all affected artifacts (and only those) have a specific version (e.g. 8.99.0-dryrun)?Do you have a log of GitHub Actions workflow run uploading the files to identify them?  If you know a specific version (and ideally have the the log of a GHA workflow run), you can use this script. The script source code has detailed usage instructions. Since the C8 monorepo currently publishes Operate, Tasklist and Zeebe a suitable deletion command for example for version 8.99.0-dryrun is:  REPOSITORY=zeebe-io ARTIFACTORY_PATH=&quot;io/camunda*&quot; VERSION=8.99.0-dryrun python delete_artifacts.py REPOSITORY=camunda-operate ARTIFACTORY_PATH=&quot;io/camunda*&quot; VERSION=8.99.0-dryrun python delete_artifacts.py REPOSITORY=camunda-zeebe-tasklist ARTIFACTORY_PATH=&quot;io/camunda*&quot; VERSION=8.99.0-dryrun python delete_artifacts.py   If you have a log of a GHA workflow run called log.txt, you can use grep to identify exact URLs of all uploaded files to Artifactory:  cat log.txt | grep &quot;Uploaded to camunda-nexus&quot; | grep -oP &quot;https://artifacts.camunda.com/[^\\s]+&quot;   You can identify affected repositories of Artifactory from a log.txt, you can use the previous command and &quot;group&quot; by repository name:  cat log.txt | grep &quot;Uploaded to camunda-nexus&quot; | grep -oP &quot;https://artifacts.camunda.com/[^\\s]+&quot; | cut -d'/' -f5 | sort | uniq   ","version":null,"tagName":"h3"},{"title":"I have another problem?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#i-have-another-problem","content":" There is a document with known problems and workarounds (if available) that should be consulted first, alongside with open issues from Issue Tracking. The user tasks of the release process have documentation attached that gives guidance.  If there is still questions, reach out via Slack.  Consider opening an incident for serious issues (see below).  Incident Process  If you discover serious issues during the Monorepo Release process (while working on any of its subtasks), you can start the incident (per usual process with /inc command in Slack).  Please select incident type: C8 Monorepo Release incident.  Who can start the incident:  Anyone participating in the current release process (Release Manager, QA Engineers, etc.)Anyone from the Orchestration cluster teams  FAQ  ","version":null,"tagName":"h3"},{"title":"1. Should I request a patch release or a customer-specific (hotfix) Docker image?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#1-should-i-request-a-patch-release-or-a-customer-specific-hotfix-docker-image","content":" üîß Request a customer-specific Docker image (hotfix) when:  The fix has not yet been merged into main or a stable branchYou want to test the fix early with a specific customer or in an internal environment (e.g., Camunda SaaS dev)You are not yet sure if the fix is correct or complete  ‚û°Ô∏è How to: follow these instructions.  Note: Hotfixes are not part of the official release process and should not be used as a substitute for patch releases. Hotfixes should be used by teams to validate a solution without impacting the general release flow.  üì¶ Request a general patch release when:  The fix has been merged and verifiedIt‚Äôs relevant to all users or addresses a broad issue, not just one customerYou‚Äôre ready to make the change available in an official release  ‚û°Ô∏è How to: use the Request Monorepo Patch release Slack workflow in this channel and fill the form.  ","version":null,"tagName":"h2"},{"title":"2. What's the git commit mechanics of the maven-release-plugin?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#2-whats-the-git-commit-mechanics-of-the-maven-release-plugin","content":" Release process roughly looks like this:  release branch is created (forked from main or stable/x.y)on the release branch, as a part of the release process, maven-release-plugin creates 2 commits sequentially:commit 1 (example): bumping pom.xml files to the version we want to release (e.g. 8.8.0-SNAPSHOT -&gt; 8.8.0-alpha6)A git tag for the release (e.g. 8.8.0-alpha6) is created from this commitThe release is built from this commit.commit 2 (example): bumping pom.xml files for the next development version (e.g. 8.8.0-alpha6 -&gt; 8.8.0-SNAPSHOT)  If one needs to retry the failed release (assuming no need to clear the released artifacts), need to do:  delete these two commits from the git historydelete the GitHub release and git tag from GitHub  ","version":null,"tagName":"h2"},{"title":"3. How do Monorepo releases relate to the Big Release Train?‚Äã","type":1,"pageTitle":"Release Process","url":"/camunda/pr-preview/pr-43929/release/#3-how-do-monorepo-releases-relate-to-the-big-release-train","content":" The Monorepo release produces core backend artifacts, while the Big Release Train bundles downstream services and UI components. The train can only depart once the Monorepo artifacts are confirmed as released.  While Monorepo (camunda/camunda) releases artifacts for:  CamundaZeebeOperateTasklist  The big release train releases:  Identity Management Component (camunda-cloud/identity)Connectors (camunda/connectors)Web Modeler (camunda/web-modeler)Monorepo ‚≠ê ‚Üê can only be done once monorepo artifacts are released (information gathered by confirm-success-release-train form)Optimize (camunda/camunda)Console (camunda/camunda-cloud-management-apps) ","version":null,"tagName":"h2"},{"title":"CI & Automation","type":0,"sectionRef":"#","url":"/camunda/pr-preview/pr-43929/ci/","content":"","keywords":"","version":null},{"title":"Git Branches‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#git-branches","content":" main: permanent branch for feature development of next C8 minor version (GitHub default branch)stable/*: long-lived branches for maintenance of past C8 minor versions (deleted on support end)release*: short-lived branches for release activities (helps to achieve code freeze) created from main or stable/*any other branch: (short-lived) branches for feature development to be merged using Pull Requests, via merge queues  ","version":null,"tagName":"h2"},{"title":"Available SNAPSHOT Artifacts‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#available-snapshot-artifacts","content":" Maven artifacts are available on Artifactory and Docker images are available on DockerHub:  Pushed commits to main branch produce: Maven artifacts with version 8.9.0-SNAPSHOT for all C8 componentsDocker images with tag SNAPSHOT for Operate, Tasklist, ZeebeDocker images with tag 8-SNAPSHOT for Optimize Pushed commits to stable/8.8 branch produce: Maven artifacts with version 8.8.0-SNAPSHOT for Operate, Tasklist, ZeebeDocker images with tag 8.8-SNAPSHOT for Optimize, Operate, Tasklist, Zeebe Pushed commits to stable/8.7 branch produce: Maven artifacts with version 8.7.0-SNAPSHOT for Operate, Tasklist, ZeebeDocker images with tag 8.7-SNAPSHOT for Operate, Tasklist, Zeebe Pushed commits to stable/optimize-8.7 branch produce: Maven artifacts with version 8.7.0-SNAPSHOT for OptimizeDocker images with tag 8.7-SNAPSHOT for Optimize  ","version":null,"tagName":"h3"},{"title":"Issue Tracking‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#issue-tracking","content":" All problems, bugs and feature requests regarding the CI of the C8 monorepo CI are tracked using GitHub Issues.  For visibility and prioritization there is the Monorepo CI project board that tracks high-level issues.  New reports of issues need to be checked against the GitHub Issues to avoid duplication: new occurrences of existing issues need to reported in comments, otherwise raise a new issue labelled area/build or reach out via Slack to the Monorepo CI DRI.  Related resources:  Monorepo CI project board (internal)Issues labelled area/build  ","version":null,"tagName":"h2"},{"title":"Prioritization‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#prioritization","content":" Prioritization of issues is done by the Monorepo CI DRI according to severity which follows from these criteria:  Impacted functionality: Highest severity for issues related to workflows that are: marked as GitHub required status checkspart of the GitHub merge queue to mainrun on main branchpart of release process Lower severity for any other workflows Amount of users impacted: Generally severity scales with the amount of affected people that interact with the monorepo (Camundi/external contributors)Can be assessed with CI health or on anecdotal level Available workarounds: Severity is lower if a workaround is available, especially if that workaround is easy to use/low effort  Dealing with reported issues that are identified as urgent/high severity:  Communicate the degraded functionality/impact and that there is an ongoing investigation to affected people.Debug problems on GitHub Actions level yourself, involve the stakeholder teams (via their medic) or subject matter experts for advice on technical details.Try to identify a (limited) workaround to unblock users.Communicate any workarounds and resolution of the problem.  ","version":null,"tagName":"h3"},{"title":"FAQ‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#faq","content":" Q: What do I do when I see the CI failing with a seemingly unrelated error?  A: Search the open GitHub Issues with the failure message to see if the problem is known: If you find an issue for the same problem, leave a comment with the new occurrance. Otherwise raise a new issue labelled area/build to start tracking that CI failure or reach out via Slack to the Monorepo CI DRI.  Q: How to deal with flaky tests that block CI?  A: Disable the flaky test(s) and comment on existing ticket or create a new one that the flaky test needs to be re-enabled after fixing it. No single test can be more important that the stability of the remaining CI system impacting dozens of developers.  ","version":null,"tagName":"h3"},{"title":"GitHub Merge Queue‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#github-merge-queue","content":" GitHub Merge Queue helps automate the Pull Request (PR) merging process by creating a temporary branch for each batch of PRs, running checks against the latest target branch, and merging changes only if the checks pass, ensuring a more streamlined and error-free workflow.  Merge queues exist per branch (one for main, one for stable/8.7, etc.) in the C8 monorepo CI and are configured independently via rulesets. So different branches can have different required status checks to control which CI workflows must be green to allow merging.  Related resources:  GitHub documentation on merge queuesMerge queue of main branch (PRs and time estimates)Ruleset for main branch  ","version":null,"tagName":"h2"},{"title":"FAQ‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#faq-1","content":" Q: Why do we use merge queues instead of manually merging PRs?  A: In repositories like the C8 monorepo with a high number of contributing engineers and high development velocity dozens of Pull Requests can get created and merged each day. Avoiding downtimes like waiting for a window to merge PRs boosts productivity and allows us to scale.  Q: Why do we have required status checks for PRs and merge queues?  A: Automated software tests increase our confidence into delivering a working software product. Required status checks are a way to technically ensure that engineers get early feedback about potential problems. This way we only merge Pull Requests to main branch that will not fail those automated tests impacting quality or other engineers. This also helps with automerging dependency updates using Renovate.  Q: What are the current required status checks for PRs and merge queue to main?  A: You can find the up2date list here: check-results check from ci.yml (Unified CI)  Q: Do those required status checks of main guarantee that all commits are green?  A: Yes, for the scope of the Unified CI except for an admin bypass of the merge queue in case of incidents.  Q: My PR had only green checks when I queued it, why was it removed from the merge queue?  A: The merge queue creates a temporary branch from the latest target branch (e.g. main) with your PR merged and then runs CI again. Your changes could be incompatible with the target branch or CI failed e.g. due to flakiness. Look up the check results for details on the CI failure.  ","version":null,"tagName":"h3"},{"title":"Unified CI‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#unified-ci","content":" &quot;Unified CI&quot; is the name of an approach to establish one central CI pipeline that runs checks for code changes of the whole monorepo instead of multiple unrelated, side-by-side pipelines for each component in the monorepo.  ","version":null,"tagName":"h2"},{"title":"Goals‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#goals","content":" This central pipeline will use change detection to run checks only when needed thus improving runtime and lowering cost. After migrating, the central CI pipeline will be the only GitHub required status check for PRs and merge queue to main thus improving UX and preventing edge cases with multiple checks and path filters.  This central pipeline will run on all Pull Requests, the merge queue to main and on push for main (and in the future other stable branches). Out of scope are scheduled and release workflows.  This topic is work-in-progress as part of #17721 to migrate remaining workflows once they meet certain criteria (short runtimes under 10 minutes and low flakiness) to the central CI.  A full run of the central CI pipeline should take ideally around 15 minutes with individual jobs only taking 10 minutes of runtime at most.  GitHub Actions pipeline code should should be de-duplicated for the same task and moved out from ci.yml into other reusable workflows named ci-&lt;subtask&gt;.yml or composite actions to keep the ci.yml short and lean.  Non-goal: Workflows that don't trigger on code changes will not be part of the Unified CI, like scheduled workflows.  ","version":null,"tagName":"h3"},{"title":"Workflow Inclusion Criteria‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#workflow-inclusion-criteria","content":" Workflows that seek inclusion to the Unified CI (and thus GitHub required status checks) need to fulfill the following criteria and best practices:  runtime of at most 10 minutes set timeout-minutes: 10 on the job levelparallelize lengthy tasks and/or use bigger runners for compute intensive tasks instrumented to emit CI health metricshigh stability (low flakiness) no CI failures for 10 consecutive builds, see here how to check ithandle flaky tests gracefully, options: retry them 3-5 times while staying in the timeout and report them via detailed test statistics API to CI healthdisable them and create a ticket to fix them long-term use Vault for secret managementfollow the GitHub Actions Cache strategy for the monorepofollow all CI Security best practices for the monorepofollow the best practices to handle flaky tests  If the required short runtime cannot be achieved, consider moving long-running tests into nightly jobs or standalone workflows that are no required status checks and don't run in the merge queue (to preserve merge velocity).  ","version":null,"tagName":"h3"},{"title":"Implementation‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#implementation","content":" This section explains how to achieve including a CI check into the Unified CI as a required status check so that it is executed only when relevant files changed in a PR.  To include a workflow fitting the criteria into the Unified CI all of the following steps have to be taken for each job of that workflow:  Change Detection: Define path filter for all file changes that should trigger the new job in this composite action. This information is relevant for the next step, make sure to: Add a new output to the composite action representing the condition when the new job should be triggered.The output have the same name as the new job it triggers.The output condition should reuse existing filters and combine them as needed.If no matching existing filter, add a new one in a step.Adjust the detect-changes job to re-expose the new output under the same name. CI Check: Relies on the previous step to run the new job only if relevant files changed. Add the new job defintion to the ci.yml file, by: Following this pattern: descriptive-job-name: # reuse information from change detection on whether to run this job if: needs.detect-changes.outputs.descriptive-job-name == 'true' needs: [detect-changes] runs-on: ubuntu-latest # or other timeout-minutes: 10 # or less permissions: {} # unless GITHUB_TOKEN is needed steps: - uses: actions/checkout@v4 # # ...ACTUAL CI CHECK STEPS HERE... # - name: Observe build status if: always() continue-on-error: true uses: ./.github/actions/observe-build-status with: build_status: ${{ job.status }} secret_vault_address: ${{ secrets.VAULT_ADDR }} secret_vault_roleId: ${{ secrets.VAULT_ROLE_ID }} secret_vault_secretId: ${{ secrets.VAULT_SECRET_ID }} It is important to depend on the detect-changes job and use the newly defined output as a condition. If the new job has many steps, you need to refactor them into a reusable workflow or composite action to keep ci.yml lean. Adding observability for CI health is required. Results Check: Include the new job as needs dependency in check-results job (required status check). This is needed so that the Unified CI is marked as failure if one of its jobs fails.  Related resources:  entrypoint and main file for pipeline code of unified CI: ci.ymlsee for example how #19423 (actionlint) and #19436 (Java unit tests) got added to unified CI  ","version":null,"tagName":"h3"},{"title":"CI Test Files‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#ci-test-files","content":" ","version":null,"tagName":"h2"},{"title":"Ownership‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#ownership","content":" Each CI test file has an owning team. The owning team can be found either through the CODEOWNERS file or on the metadata in the file itself. The CODEOWNERS file is organized and broken down by team, any additions to the file should follow that convention. The metadata on a GHA workflow file is used by a scraping tool so that it is easy to gather information about the current state of CI. You can look at the metadata for a quick overview of the owning team, where the tests live, how the test is called, and a description of what the file is actually testing  Metadata follows this structure and is placed at the beginning of a GHA workflow file  # &lt;Description of what the GHA is running and what is being tested&gt; # test location: &lt;The filepath of the tests being run&gt; # owner: &lt;The name of the owning team&gt;   ","version":null,"tagName":"h3"},{"title":"Legacy CI‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#legacy-ci","content":" &quot;Legacy CI&quot; is a name for CI tests that has not been migrated to the Unified CI. Legacy tests do not meet the inclusion criteria for Unified CI, such as running under 10 minutes.  Tests that are marked as Legacy are to be migrated to Unified CI by the owning team in the future. Once migrated, the test should live inside the ci.yml file, or be part of a workflow file that is called by it. The label of &quot;Legacy&quot; should be removed as well  ","version":null,"tagName":"h3"},{"title":"Consolidated Unit Tests‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#consolidated-unit-tests","content":" The Consolidated Unit Test job in the Unified CI runs unit tests by team and component. (For example, Operate tests owned by the Data Layer team). These tests are run by JUnit5 Suites. Each suite selects which tests to run by package. This enables the CI job to run a sub-set of all tests in a module, so that the tests being run are relevant to the owning team. Any new package for tests should be added to the relevant suite.  Suite names must follow a naming convention of {componentName}{team}TestSuite. The composite of the component and and the team is used by the CI job to select which component and team to run the tests for. For example, OperateCoreFeaturesTestSuite is used to run Core Features tests on Operate  ","version":null,"tagName":"h3"},{"title":"Naming Conventions‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#naming-conventions","content":" Names for CI tests are composed by Github Actions, which is a combination of CI job names. The composed name is shown on PRs and when viewing an individual test run in the Github UI. The composed name should follow the below naming convention to ensure consistency, clarity across the CI system, make it easy to identify the owning team, and which component is being tested.  For Names of tests in the Unified CI, the name should be structured as follows:  CI / &lt;componentName&gt; / [&lt;testType&gt;] &lt;testName&gt; / &lt;ownerName&gt; / ...   testType can be things like: UT for Unit Tests, IT for Integration Tests, Smoke for smoke tests, etc.  For example, Core Features Unit Tests for Tasklist would be appear as  CI / Tasklist / [UT] Core Features / Run Unit Tests   Importer Integration Tests for Operate would appear as  CI / Operate / [IT] Importer Tests / Data Layer / run-test   For Names for Legacy tests should be prefixed with [Legacy] &lt;componentName&gt; so that Legacy tests are organized and appear together when run on a PR. The rest of the name should be descriptive of what the test is doing.  ","version":null,"tagName":"h3"},{"title":"Renovate‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#renovate","content":" Renovate is a bot and GitHub app that automates dependency updates in software projects by scanning the source code for outdated libraries and applications, then creating Pull Requests to upgrade them to the latest versions, which helps keeping the project secure and up-to-date.  Renovate supports many package ecosystems of which we use e.g. Maven, NPM, Docker and Helm. It can scan multiple branches (e.g. main, stable/8.5) inside of one repository and raise PRs independently for those.  Renovate is configured via a JSON configuration file on the main branch. In general we allow Renovate to run and create PRs at any time to avoid lagging behind with updates.  We also want Renovate to automatically merge dependency updates when CI is green and automated tests are passing. Assuming a nearly complete test coverage the efficiency gains outweigh the risks. This is achieved by Renovate requesting to put every Pull Requests into the GitHub Merge Queue - GitHub will then ensure that required status checks pass before merging the PR.  We additionally use the renovate-approve bot to circumvent the PR reviewer requirements.  Pull Request labels that have a special meaning for Renovate:  dependencies: added by our Renovate configuration to designate dependency PRsautomerge: added by our Renovate configuration to designate dependency PRs that should get automatically mergedarea/security: added by our Renovate configuration to designate dependency PRs that fix a security vulnerabilitystop-updating: can be added by humans to tell Renovate to not rebase an open PR anymore (if the change is breaking anyways)  Related resources:  Renovate documentationDependency Dashboard (GH issue)Renovate DashboardRenovate configuration file on main branch  ","version":null,"tagName":"h2"},{"title":"FAQ‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#faq-2","content":" Q: Why do we use Renovate instead of manually looking for dependency updates?  A: We automate repetitive and error-prone tasks as much as possible to save valuable Engineering time for solving problems requiring more creativity, e.g. complex major version upgrades of dependencies.  Q: Why do we use Renovate instead of Dependabot etc.?  A: Renovate is more flexible, supports more package ecosystems, has a detailed configuration and already used successfully in other places in Camunda so we can reuse existing experience.  Q: Why does Renovate attempt to merge a PR with failing status checks?  A: Renovate will always try to automerge dependency update PRs since it does not know about CI failures. It is GitHub's task to enforce required status checks and reject the merge attempt - as long as no PR with failing status check gets actually merged, everything is working as intended.  Q: Why does Renovate not detect dependency XYZ?  A: Renovate parses and analyzes most well known dependency management files (e.g. pom.xml) automatically. Not detecting a dependency can be due to an unrecognized file format, a typo in the name, a bug in Renovate or the dependency being missing from the package ecosystem. This will usually be reported in the Renovate logs.  Q: How to access the Renovate logs?  A: Click on the most recent run in the Renovate Dashboard and make sure to show debug information.  Q: Why are updates for dependency XYZ ignored in the Renovate configuration file?  A: The reasons for manually ignoring certain updates should be described in the comments. Using git annotate to figure out who put the ignore can also be a way to get more details.  ","version":null,"tagName":"h3"},{"title":"CI Health Metrics‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#ci-health-metrics","content":" There are hundreds of CI jobs running each day in the C8 monorepo CI due to high development activity. This scale makes it challenging to assess whether there are any structural problems related to the &quot;CI health&quot; (e.g. reliability issues) that would impact developer productivity.  To achieve that for CI jobs we can collect metrics like build times, build failures and information about the hardware/runner via the CI Analytics framework. See how to instrument GHA workflows for metrics collection. We use the collected data for visualizations to get an overview of the CI health.  This topic is work-in-progress as part of #18210 to achieve better coverage, collect more different metrics for additional insights and establish a process for dealing with the results.  ","version":null,"tagName":"h2"},{"title":"Metrics Collection‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#metrics-collection","content":" Any job in any GitHub Actions workflow can be instrumented to collect information about the build status by adding one step at the end, like the following snippet shows:  jobs: my-solo-job-name: steps: # initial checkout is required! - uses: actions/checkout@v4 # keep all other steps here, then insert final step: - name: Observe build status if: always() continue-on-error: true uses: ./.github/actions/observe-build-status with: build_status: ${{ job.status }} secret_vault_address: ${{ secrets.VAULT_ADDR }} secret_vault_roleId: ${{ secrets.VAULT_ROLE_ID }} secret_vault_secretId: ${{ secrets.VAULT_SECRET_ID }}   Special handling has to be done for matrix jobs since the job name is not unique among the different matrix builds, see below:  jobs: my-matrix-job-name: strategy: matrix: identifier: [configurationA, configurationB] steps: # initial checkout is required! - uses: actions/checkout@v4 # keep all other steps here, then insert final step: - name: Observe build status if: always() continue-on-error: true uses: ./.github/actions/observe-build-status with: job_name: &quot;${{ env.GITHUB_JOB }}/${{ matrix.identifier }}&quot; build_status: ${{ job.status }} secret_vault_address: ${{ secrets.VAULT_ADDR }} secret_vault_roleId: ${{ secrets.VAULT_ROLE_ID }} secret_vault_secretId: ${{ secrets.VAULT_SECRET_ID }}   Related resources:  other examples using observe-build-statusobserve-build-status uses submit-build-status action (documentation) under the hood  ","version":null,"tagName":"h3"},{"title":"Visualization‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#visualization","content":" We visualize the collected data using an internal Grafana dashboard to analyze for high build failure rates in general and breakdowns per CI job.  Related resources:  CI Health Grafana dashboard (internal)  ","version":null,"tagName":"h3"},{"title":"CI Secret Management‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#ci-secret-management","content":" All GitHub Action workflows of the C8 monorepo CI must use Vault to retrieve secrets e.g. with the Hashicorp Vault action as a best practice. Other approaches like GitHub Action Secrets will be sunset (outside of bootstrapping connection to Vault).  Historically, different paths have been used in Vault to store secrets depending on the managing team, e.g. products/zeebe/ci or products/operate/ci. This scheme can lead to redundancies in a monorepo and should be aligned for more synergy.  Secrets for the C8 monorepo CI should be stored in Vault under the path products/camunda/ci/*. Manually managed secrets should go into products/camunda/ci/github-actions.  Related resources:  Vault for GitHub Actions (internal)  ","version":null,"tagName":"h2"},{"title":"CI Self-Hosted Runners‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#ci-self-hosted-runners","content":" GitHub offers customers to use their own machines to execute GitHub Action workflows via self-hosted runners. We use this feature in cases when more resources are needed than what GitHub can provide or at a cheaper price. See the internal documentation for what is available.  ","version":null,"tagName":"h2"},{"title":"Usage Guidelines‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#usage-guidelines","content":" How to choose which runner to use for a GHA workflow:  Use GitHub-hosted runners by default (free for public repositories)Use self-hosted runners (with -default name suffix) when a workflow needs: more resources (memory, CPU) than available on GitHub-hosted runnersARM CPU architecture  The -default self-hosted runners have no durability guarantees which makes them very cheap and the default choice, if GitHub-hosted runners are not sufficient. Exceptions: in case of reliability problems one can use the -longrunning suffix after approval by Monorepo CI DRI.  ","version":null,"tagName":"h3"},{"title":"GitHub Actions Cache‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#github-actions-cache","content":" Workflows run by GitHub Actions can avoid repeated downloads of tools and dependencies by using GitHub Actions Cache. This can shorten or avoid download times, make workflow executions faster, more robust and cheaper.  There is a web UI available and a CLI which can be used to view, analyze and delete corrupted cache entries.  Important facts about the GHA cache:  size: 10 GiB this is small for a monorepo usecase with Java, NodeJS, and many open PRs access restrictions: workflow runs can restore caches created in either the current branch or the default branch caches created for main are very usefulcaches created on other branches/Pull Requests are of very limited use, can only be used on subsequent builds of same PR cleaning policy: GitHub will immediately delete old cache entries when we exceed the 10 GiB total size counter-intuitive: caches from main (more useful than those from PRs) are deleted first if they are the oldest  Metrics on cache usage are available in CI Health Grafana dashboard (internal).  ","version":null,"tagName":"h2"},{"title":"Caching Strategy‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#caching-strategy","content":" To make the most efficient use of the limited GHA cache resources available in the monorepo and ensure consistency across many GHA workflows, we follow these guidelines:  Docker/BuildKit layers: don't write to the GHA cacheJava/Maven dependencies: do write to the GHA cache only from main and stable* branch buildsNPM/Yarn dependencies: do write to the GHA cache only from main and stable* branch buildsGolang dependencies: do write to the GHA cache only from main and stable* branch buildsCodeQL automation by GitHub: writes to the GHA cache from Pull Requests (speeds up analysis)  Implementation:  Do not use cache-from: type=gha and cache-to: type=gha parameters of docker/build-push-action.Use setup-maven-cache action.Use setup-yarn-cache action, see usage example in #21607.No implementation since Golang usage is low.  ","version":null,"tagName":"h3"},{"title":"Disable cache restoration for a Pull Request‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#disable-cache-restoration-for-a-pull-request","content":" You can temporarily turn off cache restore functionality in a PR by using the /ci-disable-cache command as described under ChatOps. This could be useful to test GHA workflows without the caching mechanism. To restore standard functionality, you need to issue the /ci-enable-cache command or drop the empty commit.  Note: Disabling cache restore mechanism is only possible on PRs.  ","version":null,"tagName":"h3"},{"title":"CI Security‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#ci-security","content":" ","version":null,"tagName":"h2"},{"title":"Permissions of GITHUB_TOKEN‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#permissions-of-github_token","content":" Every GHA workflow job is given a GITHUB_TOKEN environment variable with a valid GitHub API token by default. This token can have wide permissions which are unnecessary but open up attack surface, reducing security.  Best Practice: All GHA workflow jobs must request only actually required permissions on the GITHUB_TOKEN. Set permissions: {} by default and add what is needed.  ","version":null,"tagName":"h3"},{"title":"Usage of Third Party GitHub Actions‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#usage-of-third-party-github-actions","content":" GitHub Actions has a large ecosystem of existing useful actions from GitHub and third parties such as other companies and individuals. While reusing existing actions avoids code duplication and maintenance effort for Camunda, it increases the attack surface should any of those actions be hacked to perform malicious tasks.  Best Practice: To balance utility with risk, all GHA workflows must follow this policy:  Use the same action for the same (or similar) automation task, see recipes.Use actions only from trusted sources (GitHub or small set of select 3rd parties, settings).Move actions from Camundi personal accounts to camunda for long-term maintenance, or find replacement.  For camunda/camunda GHA workflows we use a GitHub feature to technically limit which actions can be used to:  Allow actions created by GitHub in the actions and github organizations.Allow actions in any Camunda GitHub Enterprise organization like camunda, bpmn-io, etc.Allow specific actions from 3rd parties that we need (full list see below).  If you need to use a 3rd party action not on the list, create an issue explaining the motivation and tag the Monorepo CI DRI for further discussion.  Details List of allowed 3rd party actions and reusable workflowsEnricoMi/publish-unit-test-result-action@, YunaBraska/java-info-action@, asdf-vm/actions/install@, atomicjar/testcontainers-cloud-setup-action@, aws-actions/configure-aws-credentials@, blombard/move-to-next-iteration@, bobheadxi/deployments@, browser-actions/setup-firefox@, bufbuild/buf-action@, cloudposse/github-action-matrix-outputs-read@, cloudposse/github-action-matrix-outputs-write@, codex-/return-dispatch@, dcarbone/install-jq-action@, deadsnakes/action@, dlavrenuek/conventional-changelog-action@, docker/build-push-action@, docker/login-action@, docker/metadata-action@, docker/setup-buildx-action@, docker/setup-qemu-action@, dorny/paths-filter@, fjogeleit/http-request-action@, geekyeggo/delete-artifact@, golangci/golangci-lint-action@, google-github-actions/auth@, google-github-actions/get-gke-credentials@, google-github-actions/setup-gcloud@, hadolint/hadolint-action@, hashicorp/vault-action@, hoverkraft-tech/compose-action@, jamesives/github-pages-deploy-action@, joelanford/go-apidiff@, jwalton/gh-docker-logs@, korthout/backport-action@, marocchino/sticky-pull-request-comment@, mavrosxristoforos/get-xml-info@, misiekhardcore/infra-report-action@, mshick/add-pr-comment@, mxschmitt/action-tmate@, ncipollo/release-action@, nick-fields/retry@, octokit/@, peter-evans/create-or-update-comment@, peter-evans/find-comment@, peter-evans/slash-command-dispatch@, redhat-actions/oc-login@, requarks/changelog-action@, rodrigo-lourenco-lopes/move-to-current-iteration@, rossjrw/pr-preview-action@, s4u/maven-settings-action@, s4u/setup-maven-action@, slackapi/slack-github-action@, snyk/actions/setup@, stCarolas/setup-maven@, stefanzweifel/git-auto-commit-action@, teleport-actions/auth-k8s@, teleport-actions/setup@, test-summary/action@, tibdex/github-app-token@, wagoid/commitlint-github-action@*,  ","version":null,"tagName":"h3"},{"title":"Preview Environments‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#preview-environments","content":" Engineers can request Preview Environments for specific Pull Requests of the C8 monorepo to be available via a designated URL, to allow more thorough testing and demonstration of the product features before the feature branches are merged into the base branch. For the C8 monorepo the components Identity, Operate, Optimize, Tasklist and Zeebe will get provisioned based on the camunda-platform Helm chart.  Assign the deploy-preview label to any PR to request creation of a Preview Environment. The following base branches are supported, with their corresponding Helm chart versions:  main (uses Helm chart version camunda-platform-8.8-13.x)stable/8.8 (uses Helm chart version camunda-platform-8.8-13.x)stable/8.7 (uses Helm chart version camunda-platform-8.7-12.x)stable/optimize-8.7 (uses Helm chart version camunda-platform-8.7-12.x)  Creation may take a while and a PR comment including an URL and additional info will be sent as notification. The creation/update of a Preview Environment may fail for various reasons including:  compilation errors on any code in the C8 monorepoDocker image build errorsbackwards incompatible changes in the upstream camunda-platform Helm chartbugs preventing successful startup of any included C8 component  Preview Environments are provisioned on cheap but sometimes less reliable hardware to be cost efficient, and can get automatically stopped after inactivity.  Related resources:  internal documentation  ","version":null,"tagName":"h2"},{"title":"Backporting Guidelines‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#backporting-guidelines","content":" We want crucial security, stability, cost, and other CI improvements applied to all long-living Git branches in the C8 monorepo.  ","version":null,"tagName":"h2"},{"title":"Why we need CI backports‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#why-we-need-ci-backports","content":" Changes affecting the CI such as introducing new jobs, new observability features or stability fixes are usually developed first on the main branch. We also have several stable/* branches living for multiple years to release maintenance updates.  Due to how Git branches work, every stable/* branch has its own copy of all GHA workflows at the time of forking. Those GHA workflows receive automated Renovate updates for actions. But every human-made CI change needs to be at least considered for manual backporting to ensure that crucial improvements are on all relevant branches.  ","version":null,"tagName":"h3"},{"title":"How to backport CI changes‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#how-to-backport-ci-changes","content":" Follow these instructions to backport PRs with CI changes.  It may be required to resolve Git conflicts when backporting CI changes.  ","version":null,"tagName":"h3"},{"title":"When to backport CI changes‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#when-to-backport-ci-changes","content":" If the CI change matches one of the following:  is security-related (incl dependency updates, permissions): MUST backport to all stable/* branches e.g. related are CI Security, secrets is related to cost reduction, increased reliability or observability: SHOULD backport to all stable/* branches e.g. related are CI health, GHA caching, self-hosted runners is an in-repository documentation change: SHOULD backport if it: updates procedures, guidelines, or troubleshooting steps that AI agents need for accurate assistance on stable branchesfixes incorrect information that would mislead AI agents or developers working on stable versionsadds new knowledge about practices, tools, or procedures that apply to stable branch developmentcorrects build, test, or development instructions that affect stable branch workflows is a new CI job for new product feature or test cases: backport only if the product feature is backportedis a new CI feature: backport only if required in the ticketis related to an on: schedule GHA workflow: no need to backport, only works on mainis related to Preview Environments: no need to backport, only supported on main  ","version":null,"tagName":"h3"},{"title":"Slack Notifications‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#slack-notifications","content":" All CI workflows in the camunda/camunda monorepo must use the &quot;C8 Monorepo Notifications&quot; Slack app. Messages to Slack should be send via webhooks. The webhook URLs are secrets and stored in Vault for each Slack channel.  If you need to send Slack messages to a channel for which no webhook URL exists yet, reach out via Slack to the Monorepo CI DRI to request one. They then will generate a new webhook URL for the &quot;C8 Monorepo Notifications&quot; Slack app and store it in Vault.  Webhook URL secrets can be retrieved from Vault in GitHub Actions workflows like this:  job-with-notification: steps: - uses: actions/checkout@v4 - name: Import Secrets id: secrets uses: hashicorp/vault-action@v3 with: url: ${{ secrets.VAULT_ADDR }} method: approle roleId: ${{ secrets.VAULT_ROLE_ID }} secretId: ${{ secrets.VAULT_SECRET_ID }} exportEnv: false # we rely on step outputs, no need for environment variables secrets: | secret/data/products/camunda/ci/github-actions SLACK_MYCHANNELNAME_WEBHOOK_URL; - name: Send notification uses: slackapi/slack-github-action@v2 with: webhook: ${{ steps.secrets.outputs.SLACK_MYCHANNELNAME_WEBHOOK_URL }} webhook-type: webhook-trigger # For posting a rich message using Block Kit payload: | blocks: - type: &quot;section&quot; text: type: &quot;mrkdwn&quot; text: &quot;Hello World&quot;   ","version":null,"tagName":"h2"},{"title":"ChatOps‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#chatops","content":" In the camunda/camunda monorepo certain automated workflows can be triggered by posting comments with commands on GitHub Issues and/or Pull Requests. Those commands are then processed by a GitHub Actions workflow.  Available commands:  /ci-problems comment on a Pull Request: Synopsis: Triggers a script that analyzes all CI runs related to that PR for CI failures and posts summary as new PR comment.Use case: Can be used by any engineer to get actionable hints on how to address CI problems in a PR.Capabilities: detect problems with self-hosted runners (incl links to dashboards + Kubernetes logs)pipeline timeoutsDockerHub connection problemsdeep links to GHA logs for generic job failures /ci-disable-cache comment on a Pull Request: Synopsis: Adds a new label ci:no-cache to the list of labels of the Pull Request and creates a new empty commit to trigger a new CI run without cache restoration.Use case: Can be used by any engineer to test workflows run from scratch without cache restoration. /ci-enable-cache comment on a Pull Request: Synopsis: Removes the ci:no-cache label from the list of labels of the Pull Request and creates a new empty commit to trigger a new CI run.Use case: Complements the /ci-disable-cache commands and can be used to restore CI regular cache restoration step.  ","version":null,"tagName":"h2"},{"title":"Flaky tests‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#flaky-tests","content":" Tests can be viewed as &quot;flaky&quot; when they are not consistenly passing although neither the source code, nor the test code, nor the environment has been meaningfully changed.  We should aim to have all tests consistently passing, avoid introducing new flaky tests and implement our observability tooling to detect and improve existing flaky tests. This allows for better developer experience and smoother processes like automated dependency updates.  GitHub Action workflows with Maven testing Java code should use the flaky-test-extractor-maven-plugin and report the resulting detailed flaky test statistics to our CI health database.  Related resources:  the Flaky tests dashboard (internal)  ","version":null,"tagName":"h2"},{"title":"flaky-test-extractor-maven-plugin‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#flaky-test-extractor-maven-plugin","content":" Some Maven modules in the monorepo rerun failing Java tests multiple times (e.g. 3 times, configurable) when they fail and use the flaky-test-extractor-maven-plugin:  if a test succeeds at least once during the retries, it is classified as &quot;flaky&quot; by this plugin flaky tests get reported via CI Health metrics and can be viewed on the Flaky tests dashboardflaky tests do not cause build failures if a test fails on all retries, it is classified as &quot;failed&quot; this will cause the whole build to failsee the FAQ on how to deal with such cases  ","version":null,"tagName":"h3"},{"title":"License Checks‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#license-checks","content":" We use FOSSA to check dependencies for license compliance with Camunda's policies in order to detect risks early and be aware of licenses of our BOM.  The scan is performed by a GitHub Actions workflows for:  each tageach commit pushed to main and stable* (8.6+) brancheseach Pull Request opened against the above branches  ","version":null,"tagName":"h2"},{"title":"Troubleshooting‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#troubleshooting","content":" ","version":null,"tagName":"h2"},{"title":"How to deal with CI alerts that fire?‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#how-to-deal-with-ci-alerts-that-fire","content":" Follow the Monorepo CI medic routines and check out the available CI runbooks for each alert.  ","version":null,"tagName":"h3"},{"title":"Why is my CI check failing?‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#why-is-my-ci-check-failing","content":" There can be many factors influencing that and it is sometimes hard to find the root caues. Below list should provide guidance:  Try to rerun the failing CI check(s) at least to overcome transient problems.If on a Pull Request, consider whether the code changes on that Pull Request might cause the CI check failure.Check if there is an open issue about that failing CI check, e.g. by searching for the error message.Ask Copilot about the failure using the Explain error button If this doesn't work, find and google the error message. If the failing CI checks are not part of the Unified CI, contact their owner and see if those CI checks are known to be unstable or flaky. Technically, failing CI checks outside the Unified CI do not prevent merging a PR. If the owners of those failing CI checks agree, you can still merge. If your PR is removed from the merge queue, check if concurrently there was another PR merged that changes code which your code depends on (e.g. leading to compilation errors in the merge queue).If a check from the Unified CI is failing on main or a stable branch, try to find the first build with that failing check and investigate the recently merged code changes. Experience shows that most CI check failures are (indirectly) caused by camunda/camunda code changes, and not by external factors like 3rd party services or infrastructure.CI Health metrics can also be used to narrow down the time range, less precise. Reach out on Slack for help!  ","version":null,"tagName":"h3"},{"title":"How to verify that a CI check is robust and stable, not flaky?‚Äã","type":1,"pageTitle":"CI & Automation","url":"/camunda/pr-preview/pr-43929/ci/#how-to-verify-that-a-ci-check-is-robust-and-stable-not-flaky","content":" First, create a dedicated branch YOURBRANCHNAME which can be used as a reference for running the CI check later.  If you are working on fixing a flaky test, push the code or build pipeline change(s) that you believe remove the flakiness onto that branch.  Is your CI check part of the Unified CI's ci.yml?  No, but it runs on Pull Requests. Then you have to create a draft PR for YOURBRANCHNAME and manually trigger reruns of the check in question. Yes! Then you can use the GitHub CLI tool to start repeated runs. Optional: remove CI checks you are not interested in from the ci.yml on YOURBRANCHNAME to speed up the execution and save resources. Open a new terminal, go to your checkout of camunda/camunda and execute in bash shell: for i in {1..10}; do gh workflow run ci.yml --ref YOURBRANCHNAME; done This loop will take a while (1 hour or more depending on the CI check) so let it run in the background. After it finished, visit https://github.com/camunda/camunda/actions/workflows/ci.yml?query=branch%3AYOURBRANCHNAME and see if there are any failures (indicates lack of robustness). ","version":null,"tagName":"h3"}],"options":{"indexBaseUrl":true,"highlightResult":true,"disableVersioning":true,"id":"default"}}
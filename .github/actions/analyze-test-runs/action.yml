---
name: Analyze test runs

description: Check for duplicated test runs from a maven build output file and fail if found.

inputs:
  buildOutputFilePath:
    description: 'Path to the build log file.'
    required: true
  skipSummary:
    description: "Whether to run the test-summary action, it might run into problems an large test outputs"
    default: "false"
    required: false

outputs:
  flakyTests:
    description: "A collection of flaky tests, if there are any"
    value: ${{ steps.find-flakes.outputs.FLAKY_TESTS }}

runs:
  using: composite
  steps:
  - name: Test Summary
    uses: test-summary/action@v2
    if: ${{ inputs.skipSummary == 'false' }}
    with:
      paths: |
        **/target/failsafe-reports/TEST-*.xml
        **/target/surefire-reports/TEST-*.xml
  - name: Find flaky tests
    id: find-flakes
    shell: bash
    env:
      BUILD_OUTPUT_FILE_PATH: ${{ inputs.buildOutputFilePath }}
    run: |
      set -eoux
      if [ ! -s "$BUILD_OUTPUT_FILE_PATH" ]; then
        echo "::error::Build output file does not exist or is empty!"
        exit 1
      fi

      # Extracting flaky tests
      # Based on old Jenkins script
      # https://github.com/camunda/camunda/blob/stable/8.1/.ci/scripts/lib/flaky-tests.sh
      if grep -q "\[WARNING\] Flakes:" "$BUILD_OUTPUT_FILE_PATH"; then
        irOutputFile=$(mktemp)

        # Extracting the essential lines
        awk '/^\[WARNING\] Flakes:.*$/{flag=1}/^\[ERROR\] Tests run:.*Flakes: [0-9]*$/{print;flag=0}flag' "$BUILD_OUTPUT_FILE_PATH" > ${irOutputFile}

        # To cover cases where we use parameterized tests like
        # [WARNING]  io.camunda.zeebe.engine.state.BanInstanceTest.shouldBanInstance[PROCESS_MESSAGE_SUBSCRIPTION DELETE should ban instance true]
        # We grep the WARNING line and set the first argument to an empty string
        flakyTests=$(grep -E "\[WARNING\] [a-z]+\." ${irOutputFile} | awk '{$1=""; print $0}')

        # To support multi-line string in output we have to work with EOF delimiter
        # https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#example-of-a-multiline-string
        {
          echo 'FLAKY_TESTS<<EOF'
          echo "$flakyTests"
          echo EOF
        } >> $GITHUB_OUTPUT

        echo "::warning::Found flaky tests!\n ${flakyTests}"
      fi
  - name: Comment flaky tests on PR
    if: steps.find-flakes.outputs.FLAKY_TESTS != ''
    uses: actions/github-script@v7
    with:
      github-token: ${{ github.token }}
      script: |
        const flakyTests = `${{ steps.find-flakes.outputs.FLAKY_TESTS }}`;
        const prNumber = context.issue.number;
        const owner = context.repo.owner;
        const repo = context.repo.repo;

        // New functionality: Map flaky tests to files and check for recent commits
        let touchedFilesInfo = '';
        let mentionedAuthors = new Set();

        try {
          // Get files changed in this PR
          const { data: prFiles } = await github.rest.pulls.listFiles({
            owner,
            repo,
            pull_number: prNumber,
          });

          const changedFiles = prFiles.map(file => file.filename);

          // Process each flaky test to find corresponding files
          const flakyTestLines = flakyTests.trim().split('\n').filter(line => line.trim());

          for (const testLine of flakyTestLines) {
            // Extract test class name (e.g., "io.camunda.search.SomeTest" from the flaky test output)
            const testClassMatch = testLine.match(/([a-zA-Z][a-zA-Z0-9]*\.)+[a-zA-Z][a-zA-Z0-9]*\.[A-Z][a-zA-Z0-9]*Test/);

            if (testClassMatch) {
              const testClass = testClassMatch[0];

              // Convert class name to potential file paths
              const classPath = testClass.replace(/\./g, '/');
              const possiblePaths = [
                `${classPath}.java`,
                `src/test/java/${classPath}.java`,
                `src/main/java/${classPath}.java`
              ];

              // Check if any of these paths match changed files
              for (const possiblePath of possiblePaths) {
                const matchingFile = changedFiles.find(file =>
                  file.endsWith(possiblePath) || file.includes(testClass.split('.').pop())
                );

                if (matchingFile) {
                  // Get commit info for this file
                  const { data: commits } = await github.rest.pulls.listCommits({
                    owner,
                    repo,
                    pull_number: prNumber,
                  });

                  // Find the most recent commit that modified this file
                  for (const commit of commits.reverse()) {
                    const { data: commitFiles } = await github.rest.repos.getCommit({
                      owner,
                      repo,
                      ref: commit.sha,
                    });

                    const modifiedThisFile = commitFiles.files?.some(file => file.filename === matchingFile);

                    if (modifiedThisFile && commit.author?.login) {
                      touchedFilesInfo += `\n- ðŸ“ \`${matchingFile}\` (Test: \`${testClass}\`) - Last modified by @${commit.author.login} in [${commit.sha.substring(0, 7)}](${commit.html_url})`;
                      mentionedAuthors.add(commit.author.login);
                      break; // Found the most recent commit for this file
                    }
                  }
                  break; // Found matching file, no need to check other paths
                }
              }
            }
          }
        } catch (error) {
          console.log(`Could not analyze file changes: ${error.message}`);
        }

        // Build the comment body (preserving original format and adding new info)
        let body = `
          ### Oh! We've got ourselves flaky ones!
          \`\`\`
          ${flakyTests}
          \`\`\``;

        // Add personalized section if we found touched files
        if (touchedFilesInfo) {
          const authorsArray = Array.from(mentionedAuthors);
          const authorMentions = authorsArray.length > 1
            ? `Hey ${authorsArray.slice(0, -1).map(author => `@${author}`).join(', ')} and @${authorsArray[authorsArray.length - 1]}! ðŸ‘‹`
            : `Hey @${authorsArray[0]}! ðŸ‘‹`;

          body += `

          ### ðŸŽ¯ Heads up to recent contributors!
          ${authorMentions}

          I noticed some of these flaky tests are in files you recently modified:
          ${touchedFilesInfo}

          Since you've been working on these files, would you have a moment to take a look at the flaky tests? You might have insights into what could be causing the instability. No pressure though - flaky tests can be tricky! ðŸ¤”`;
        }

        body += `

          Related to your code? Maybe.
          Fixable now? Maybe not.
          Mind giving it a look? Or don't, but I will remember, and
          ![I'll be back](https://media.tenor.com/p2Ie017Zwu8AAAAM/exterminador-do.gif)
        `;

        // Find existing comments (preserving original logic)
        const comments = await github.rest.issues.listComments({
          owner,
          repo,
          issue_number: prNumber,
        });

        // Get comments about flakyness (preserving original logic)
        const marker = `${flakyTests}`;
        const botComment = comments.data.find(comment =>
          comment.user.type === "Bot" && comment.body.includes(marker)
        );

        if (botComment) {
          await github.rest.issues.updateComment({
            owner,
            repo,
            comment_id: botComment.id,
            body: body
          });
          console.log("âœ… Updated existing flaky test comment");
        } else {
          await github.rest.issues.createComment({
            owner,
            repo,
            issue_number: prNumber,
            body: body
          });
          console.log("âœ… Created new flaky test comment");
        }

  - name: Unfinished tests
    if: failure() || cancelled()
    shell: bash
    env:
      BUILD_OUTPUT_FILE_PATH: ${{ inputs.buildOutputFilePath }}
    run: |
      if [ ! -s "$BUILD_OUTPUT_FILE_PATH" ]; then
        echo "::error::Build output file does not exist or is empty!"
        exit 1
      fi
      running=$(mktemp)
      finished=$(mktemp)
      unfinished=$(mktemp)
      grep -oP "\[INFO\] Running \K(.*)$" "$BUILD_OUTPUT_FILE_PATH" > "$running"
      grep -oP 'Tests run.*?-- in \K(.*)$' "$BUILD_OUTPUT_FILE_PATH" > "$finished"
      sort $running $finished | uniq -u > "$unfinished"
      if [ -s "$unfinished" ]; then
        echo "### âš ï¸ Unfinished test runs" >> $GITHUB_STEP_SUMMARY
        cat $unfinished >> $GITHUB_STEP_SUMMARY
      fi
      exit 0
